"""
Test Suite for Claude-Enhanced OpenWebUI Plugin
==============================================

Bu dosya Claude-Enhanced eklentisinin kapsamlÄ± test paketini iÃ§erir.
TÃ¼m fonksiyonlarÄ±n doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve beklenen performansÄ± saÄŸladÄ±ÄŸÄ±nÄ± doÄŸrular.

Usage:
    python test_claude_enhanced.py
    
    # Sadece belirli testleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
    python -m pytest test_claude_enhanced.py::test_reasoning_engine -v
"""

import unittest
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any
import sys
import os

# Plugin modÃ¼lÃ¼nÃ¼ import et
try:
    from functions import (
        claude_enhanced_thinking,
        discover_and_use_tools,
        agentic_planning,
        real_world_adaptation,
        claude_agent,
        ClaudeEnhancedAgent,
        ReasoningStep,
        ThinkingChain,
        AgentGoal,
        ToolCapability
    )
except ImportError as e:
    print(f"âŒ Plugin import hatasÄ±: {e}")
    print("functions.py dosyasÄ±nÄ±n mevcut dizinde olduÄŸundan emin olun.")
    sys.exit(1)

class TestClaudeEnhancedPlugin(unittest.TestCase):
    """Claude Enhanced Plugin iÃ§in ana test sÄ±nÄ±fÄ±"""
    
    def setUp(self):
        """Her test Ã¶ncesi Ã§alÄ±ÅŸacak setup"""
        # Test iÃ§in temiz bir agent instance'Ä± oluÅŸtur
        self.test_agent = ClaudeEnhancedAgent()
        
        # Test verileri
        self.sample_queries = [
            "Machine learning nedir ve nasÄ±l Ã§alÄ±ÅŸÄ±r?",
            "Åirketimiz iÃ§in en iyi pazarlama stratejisi nedir?",
            "Python'da veritabanÄ± baÄŸlantÄ±sÄ± nasÄ±l yapÄ±lÄ±r?",
            "KarmaÅŸÄ±k bir proje nasÄ±l yÃ¶netilir?"
        ]
        
        self.sample_apis = [
            {
                "name": "weather_api",
                "description": "Hava durumu bilgisi alma",
                "parameters": {"location": "str", "days": "int"}
            },
            {
                "name": "database_api",
                "description": "VeritabanÄ± iÅŸlemleri",
                "parameters": {"query": "str", "table": "str"}
            }
        ]
        
    def test_agent_initialization(self):
        """Agent baÅŸlatma testleri"""
        print("\nğŸ§ª Agent BaÅŸlatma Testi...")
        
        # Agent'Ä±n doÄŸru ÅŸekilde baÅŸlatÄ±ldÄ±ÄŸÄ±nÄ± kontrol et
        self.assertIsInstance(self.test_agent, ClaudeEnhancedAgent)
        self.assertEqual(len(self.test_agent.thinking_history), 0)
        self.assertEqual(len(self.test_agent.goals), 0)
        self.assertGreater(len(self.test_agent.available_tools), 0)
        
        # VarsayÄ±lan araÃ§larÄ±n yÃ¼klendiÄŸini kontrol et
        self.assertIn("web_search", self.test_agent.available_tools)
        self.assertIn("code_analysis", self.test_agent.available_tools)
        self.assertIn("planning", self.test_agent.available_tools)
        
        print("âœ… Agent baÅŸarÄ±yla baÅŸlatÄ±ldÄ±")
        
    def test_thinking_chain_creation(self):
        """DÃ¼ÅŸÃ¼nme zinciri oluÅŸturma testleri"""
        print("\nğŸ§ª DÃ¼ÅŸÃ¼nme Zinciri Testi...")
        
        # DÃ¼ÅŸÃ¼nme adÄ±mÄ± ekleme
        step = self.test_agent.add_thinking_step(
            ReasoningStep.ANALYSIS,
            "Test analizi",
            0.9
        )
        
        self.assertIsInstance(step, ThinkingChain)
        self.assertEqual(step.step, ReasoningStep.ANALYSIS)
        self.assertEqual(step.content, "Test analizi")
        self.assertEqual(step.confidence, 0.9)
        self.assertEqual(len(self.test_agent.thinking_history), 1)
        
        print("âœ… DÃ¼ÅŸÃ¼nme zinciri baÅŸarÄ±yla oluÅŸturuldu")
        
    def test_reasoning_engine(self):
        """Reasoning engine testleri"""
        print("\nğŸ§ª Reasoning Engine Testi...")
        
        for query in self.sample_queries[:2]:  # Ä°lk 2 sorguyu test et
            print(f"  ğŸ” Test ediliyor: {query[:50]}...")
            
            result = self.test_agent.chain_of_thought_reasoning(query)
            
            # SonuÃ§ yapÄ±sÄ±nÄ± kontrol et
            self.assertIn("reasoning_chain", result)
            self.assertIn("final_answer", result)
            self.assertIn("confidence_score", result)
            self.assertIn("thinking_process", result)
            
            # Reasoning chain'in doÄŸru yapÄ±da olduÄŸunu kontrol et
            self.assertIsInstance(result["reasoning_chain"], list)
            self.assertGreater(len(result["reasoning_chain"]), 0)
            
            # Confidence score'un geÃ§erli aralÄ±kta olduÄŸunu kontrol et
            self.assertGreaterEqual(result["confidence_score"], 0.0)
            self.assertLessEqual(result["confidence_score"], 1.0)
            
            # Final answer'Ä±n boÅŸ olmadÄ±ÄŸÄ±nÄ± kontrol et
            self.assertIsInstance(result["final_answer"], str)
            self.assertGreater(len(result["final_answer"]), 0)
            
        print("âœ… Reasoning engine testleri baÅŸarÄ±lÄ±")
        
    def test_claude_enhanced_thinking_function(self):
        """Claude enhanced thinking function testleri"""
        print("\nğŸ§ª Claude Enhanced Thinking Function Testi...")
        
        # Basit kullanÄ±m testi
        result = claude_enhanced_thinking("Python nedir?")
        self.assertIsInstance(result, str)
        self.assertIn("Claude-Enhanced Thinking Response", result)
        
        # GeliÅŸmiÅŸ parametreler ile test
        result = claude_enhanced_thinking(
            query="KarmaÅŸÄ±k bir analiz problemi",
            reasoning_depth=4,
            enable_critical_thinking=True
        )
        self.assertIsInstance(result, str)
        self.assertIn("DÃ¼ÅŸÃ¼nme SÃ¼reci", result)
        
        print("âœ… Claude enhanced thinking function testleri baÅŸarÄ±lÄ±")
        
    def test_tool_discovery_and_usage(self):
        """AraÃ§ keÅŸif ve kullanÄ±m testleri"""
        print("\nğŸ§ª Tool Discovery Testi...")
        
        # Tool discovery function'Ä± test et
        result = discover_and_use_tools(
            task_description="Hava durumu bilgisi al ve veritabanÄ±na kaydet",
            available_apis=self.sample_apis
        )
        
        self.assertIsInstance(result, str)
        self.assertIn("AkÄ±llÄ± AraÃ§ KullanÄ±mÄ±", result)
        self.assertIn("Belirlenen AraÃ§lar", result)
        
        # Agent'Ä±n araÃ§larÄ± doÄŸru ÅŸekilde belirlediÄŸini kontrol et
        suitable_tools = self.test_agent._identify_suitable_tools(
            "VeritabanÄ± analizi yap",
            self.sample_apis
        )
        
        self.assertIsInstance(suitable_tools, list)
        # En az bir araÃ§ belirlenmiÅŸ olmalÄ±
        if len(suitable_tools) > 0:
            self.assertIn("name", suitable_tools[0])
            self.assertIn("relevance_score", suitable_tools[0])
            
        print("âœ… Tool discovery testleri baÅŸarÄ±lÄ±")
        
    def test_agentic_planning_function(self):
        """Agentic planning function testleri"""
        print("\nğŸ§ª Agentic Planning Testi...")
        
        # Agentic planning function'Ä± test et
        result = agentic_planning(
            objective="Web sitesi performansÄ±nÄ± iyileÅŸtir",
            constraints=["BÃ¼tÃ§e: $10K", "SÃ¼re: 2 ay"],
            time_horizon="medium"
        )
        
        self.assertIsInstance(result, str)
        self.assertIn("Agentic Planning Response", result)
        self.assertIn("Hedef Analizi", result)
        self.assertIn("Stratejik Plan", result)
        self.assertIn("Risk Analizi", result)
        
        print("âœ… Agentic planning testleri baÅŸarÄ±lÄ±")
        
    def test_real_world_adaptation_function(self):
        """Real world adaptation function testleri"""
        print("\nğŸ§ª Real World Adaptation Testi...")
        
        # Real world adaptation function'Ä± test et
        result = real_world_adaptation(
            context="Uzaktan Ã§alÄ±ÅŸma ortamÄ±nda ekip yÃ¶netimi",
            environmental_factors=["Zaman farklarÄ±", "Ä°letiÅŸim zorluklarÄ±"],
            adaptation_goals=["Verimlilik artÄ±ÅŸÄ±", "Ekip uyumu"]
        )
        
        self.assertIsInstance(result, str)
        self.assertIn("Real-World Adaptation Analysis", result)
        self.assertIn("BaÄŸlam Analizi", result)
        self.assertIn("Adaptasyon Stratejileri", result)
        
        print("âœ… Real world adaptation testleri baÅŸarÄ±lÄ±")
        
    def test_learning_and_pattern_recognition(self):
        """Ã–ÄŸrenme ve kalÄ±p tanÄ±ma testleri"""
        print("\nğŸ§ª Learning ve Pattern Recognition Testi...")
        
        # BirkaÃ§ query Ã§alÄ±ÅŸtÄ±rarak Ã¶ÄŸrenme sistemini test et
        initial_patterns = len(self.test_agent.learned_patterns)
        
        for i, query in enumerate(self.sample_queries):
            self.test_agent.chain_of_thought_reasoning(query)
            
        # Yeni kalÄ±plar Ã¶ÄŸrenildiÄŸini kontrol et
        final_patterns = len(self.test_agent.learned_patterns)
        self.assertGreaterEqual(final_patterns, initial_patterns)
        
        print(f"âœ… {final_patterns - initial_patterns} yeni kalÄ±p Ã¶ÄŸrenildi")
        
    def test_error_handling(self):
        """Hata yÃ¶netimi testleri"""
        print("\nğŸ§ª Error Handling Testi...")
        
        # BoÅŸ query ile test
        result = claude_enhanced_thinking("")
        self.assertIsInstance(result, str)
        
        # None deÄŸerler ile test
        result = discover_and_use_tools(
            task_description="test",
            available_apis=None
        )
        self.assertIsInstance(result, str)
        
        # GeÃ§ersiz parametreler ile test
        result = agentic_planning(
            objective="",
            constraints=None,
            time_horizon="invalid"
        )
        self.assertIsInstance(result, str)
        
        print("âœ… Error handling testleri baÅŸarÄ±lÄ±")
        
    def test_performance_metrics(self):
        """Performans metrik testleri"""
        print("\nğŸ§ª Performance Metrics Testi...")
        
        import time
        
        # Reasoning performance test
        start_time = time.time()
        result = claude_enhanced_thinking("Basit bir test sorusu")
        reasoning_time = time.time() - start_time
        
        print(f"  â±ï¸ Reasoning sÃ¼resi: {reasoning_time:.2f} saniye")
        self.assertLess(reasoning_time, 5.0)  # 5 saniyeden az olmalÄ±
        
        # Tool discovery performance test
        start_time = time.time()
        result = discover_and_use_tools("Test gÃ¶revi", self.sample_apis)
        tool_time = time.time() - start_time
        
        print(f"  â±ï¸ Tool discovery sÃ¼resi: {tool_time:.2f} saniye")
        self.assertLess(tool_time, 3.0)  # 3 saniyeden az olmalÄ±
        
        print("âœ… Performance testleri baÅŸarÄ±lÄ±")
        
    def test_memory_usage(self):
        """Bellek kullanÄ±m testleri"""
        print("\nğŸ§ª Memory Usage Testi...")
        
        import psutil
        import os
        
        # BaÅŸlangÄ±Ã§ bellek kullanÄ±mÄ±
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # BirÃ§ok operation Ã§alÄ±ÅŸtÄ±r
        for i in range(10):
            claude_enhanced_thinking(f"Test query {i}")
            discover_and_use_tools(f"Test task {i}", self.sample_apis)
            
        # Son bellek kullanÄ±mÄ±
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        print(f"  ğŸ’¾ Bellek artÄ±ÅŸÄ±: {memory_increase:.2f} MB")
        self.assertLess(memory_increase, 100)  # 100 MB'dan az artÄ±ÅŸ olmalÄ±
        
        print("âœ… Memory usage testleri baÅŸarÄ±lÄ±")
        
    def test_concurrent_operations(self):
        """EÅŸzamanlÄ± iÅŸlem testleri"""
        print("\nğŸ§ª Concurrent Operations Testi...")
        
        import threading
        import time
        
        results = []
        
        def worker(query_id):
            result = claude_enhanced_thinking(f"Concurrent test {query_id}")
            results.append(result)
            
        # 3 eÅŸzamanlÄ± thread baÅŸlat
        threads = []
        for i in range(3):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)
            thread.start()
            
        # TÃ¼m thread'lerin bitmesini bekle
        for thread in threads:
            thread.join()
            
        # SonuÃ§larÄ± kontrol et
        self.assertEqual(len(results), 3)
        for result in results:
            self.assertIsInstance(result, str)
            
        print("âœ… Concurrent operations testleri baÅŸarÄ±lÄ±")
        
def run_comprehensive_tests():
    """KapsamlÄ± test paketini Ã§alÄ±ÅŸtÄ±r"""
    print("ğŸš€ Claude-Enhanced Plugin KapsamlÄ± Test Paketi BaÅŸlatÄ±lÄ±yor...\n")
    print("=" * 60)
    
    # Test suite oluÅŸtur
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestClaudeEnhancedPlugin)
    
    # Test runner yapÄ±landÄ±r
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
    
    # Testleri Ã§alÄ±ÅŸtÄ±r
    start_time = datetime.now()
    result = runner.run(test_suite)
    end_time = datetime.now()
    
    # SonuÃ§larÄ± Ã¶zetle
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST SONUÃ‡LARI")
    print("=" * 60)
    
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"ğŸ§ª Toplam Test: {total_tests}")
    print(f"âœ… BaÅŸarÄ±lÄ±: {total_tests - failures - errors}")
    print(f"âŒ BaÅŸarÄ±sÄ±z: {failures}")
    print(f"âš ï¸ Hata: {errors}")
    print(f"ğŸ“ˆ BaÅŸarÄ± OranÄ±: {success_rate:.1f}%")
    print(f"â±ï¸ Toplam SÃ¼re: {end_time - start_time}")
    
    if failures > 0:
        print("\nâŒ BAÅARISIZ TESTLER:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
            
    if errors > 0:
        print("\nâš ï¸ HATALI TESTLER:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
            
    print("\n" + "=" * 60)
    
    if success_rate >= 90:
        print("ğŸ‰ Plugin test paketini baÅŸarÄ±yla geÃ§ti!")
        return True
    else:
        print("âš ï¸ Plugin bazÄ± testlerde sorun yaÅŸÄ±yor. DetaylarÄ± inceleyin.")
        return False
        
def run_performance_benchmark():
    """Performans benchmark'Ä± Ã§alÄ±ÅŸtÄ±r"""
    print("\nğŸƒ PERFORMANS BENCHMARK'I")
    print("=" * 40)
    
    import time
    
    # Reasoning performance
    queries = [
        "Basit soru",
        "Orta seviye analiz gerektiren soru hakkÄ±nda dÃ¼ÅŸÃ¼n",
        "KarmaÅŸÄ±k, Ã§ok adÄ±mlÄ± analiz gerektiren uzun bir soru ve bu sorunun cevabÄ± iÃ§in detaylÄ± planlama yap"
    ]
    
    for i, query in enumerate(queries):
        start_time = time.time()
        result = claude_enhanced_thinking(query)
        end_time = time.time()
        
        query_type = ["Basit", "Orta", "KarmaÅŸÄ±k"][i]
        print(f"ğŸ“Š {query_type} Query: {end_time - start_time:.2f}s")
        
    # Tool discovery performance
    start_time = time.time()
    for i in range(5):
        discover_and_use_tools(f"Test task {i}", [])
    end_time = time.time()
    
    print(f"ğŸ› ï¸ Tool Discovery (5x): {end_time - start_time:.2f}s")
    
    # Memory efficiency
    import psutil
    import os
    process = psutil.Process(os.getpid())
    memory_mb = process.memory_info().rss / 1024 / 1024
    print(f"ğŸ’¾ Bellek KullanÄ±mÄ±: {memory_mb:.1f} MB")
    
    print("=" * 40)

if __name__ == "__main__":
    try:
        # KapsamlÄ± testleri Ã§alÄ±ÅŸtÄ±r
        success = run_comprehensive_tests()
        
        # Performans benchmark'Ä± Ã§alÄ±ÅŸtÄ±r
        run_performance_benchmark()
        
        # SonuÃ§
        if success:
            print("\nğŸ¯ TÃœM TESTLER BAÅARIYLA TAMAMLANDI!")
            print("âœ¨ Plugin production-ready durumda!")
        else:
            print("\nâš ï¸ BazÄ± testler baÅŸarÄ±sÄ±z oldu. LÃ¼tfen loglarÄ± inceleyin.")
            
    except Exception as e:
        print(f"\nâŒ Test suite Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken hata oluÅŸtu: {e}")
        import traceback
        traceback.print_exc()
        
    print("\nğŸ‘‹ Test sÃ¼reci tamamlandÄ±!")
